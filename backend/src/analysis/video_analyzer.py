"""
Video analysis prototype using Gemini vision capabilities.
Extracts hooks, CTAs, visual elements, on-screen text, and product showcase from video ads.
"""
import os
import json
from typing import Dict, Any, Optional
from pathlib import Path

from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()
DEFAULT_MODEL = os.environ.get("GEMINI_MODEL", "models/gemini-2.0-flash")


def _ensure_api_key():
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        raise RuntimeError("GOOGLE_API_KEY is not set. Please export your Google AI Studio API key.")
    genai.configure(api_key=api_key)


def analyze_video_file(
    video_path: str,
    meta: Optional[Dict[str, Any]] = None,
    model_name: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Analyze a video file using Gemini vision model.
    
    Args:
        video_path: Path to the cached video file
        meta: Optional metadata about the creative (page_name, platforms, etc.)
        model_name: Gemini model to use (default: gemini-1.5-flash)
    
    Returns:
        Dictionary with structured analysis
    """
    _ensure_api_key()
    
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"Video file not found: {video_path}")
    
    # Upload video to Gemini
    print(f"ðŸ“¤ Uploading video: {Path(video_path).name}")
    video_file = genai.upload_file(path=video_path)
    print(f"âœ… Uploaded as: {video_file.name}")
    
    # Wait for file to become active
    import time
    print("â³ Waiting for file to be processed...")
    while video_file.state.name == "PROCESSING":
        time.sleep(2)
        video_file = genai.get_file(video_file.name)
    
    if video_file.state.name != "ACTIVE":
        raise RuntimeError(f"File processing failed: {video_file.state.name}")
    print("âœ… File is ready")
    
    # Try to use specified model, fallback to working alternatives
    model_to_use = model_name or DEFAULT_MODEL
    
    # Ensure model name has correct prefix
    if not model_to_use.startswith("models/"):
        model_to_use = f"models/{model_to_use}"
    
    try:
        model = genai.GenerativeModel(model_to_use)
    except Exception as e:
        print(f"âš ï¸  Model {model_to_use} not available, trying models/gemini-2.0-flash...")
        try:
            model = genai.GenerativeModel("models/gemini-2.0-flash")
        except Exception:
            print("âš ï¸  Trying models/gemini-2.0-pro-exp...")
            model = genai.GenerativeModel("models/gemini-2.0-pro-exp")
    
    # Build context
    context = ""
    if meta:
        context = f"\nÐœÐµÑ‚Ð°Ð´Ð°Ð½Ñ– ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ñƒ:\n{json.dumps(meta, ensure_ascii=False, indent=2)}\n"
    
    # Prompt for video analysis (Ukrainian) - Performance Marketing oriented
    prompt = f"""Ð Ð¾Ð»ÑŒ: Ð¢Ð¸ â€” ÐµÐºÑÐ¿ÐµÑ€Ñ‚Ð½Ð¸Ð¹ Performance Marketing Creative Strategist. Ð¢Ð²Ð¾Ñ” Ð·Ð°Ð²Ð´Ð°Ð½Ð½Ñ â€” Ð½Ðµ Ð¿Ñ€Ð¾ÑÑ‚Ð¾ Ð¾Ð¿Ð¸ÑÐ°Ñ‚Ð¸ Ð²Ñ–Ð´ÐµÐ¾, Ð° Ð¿Ñ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ²Ð°Ñ‚Ð¸ Ð¹Ð¾Ð³Ð¾ ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ, Ð²Ð¸Ð·Ð½Ð°Ñ‡Ð¸Ñ‚Ð¸ Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ñ– Ñ‚Ñ€Ð¸Ð³ÐµÑ€Ð¸ Ñ‚Ð° Ð½Ð°Ð´Ð°Ñ‚Ð¸ Ð´Ñ–Ñ”Ð²Ñ– Ð³Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð¸ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ.

ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ†ÐµÐ¹ Ð²Ñ–Ð´ÐµÐ¾ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð² ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð°, ÑÐ¿Ð¸Ñ€Ð°ÑŽÑ‡Ð¸ÑÑŒ Ð½Ð° Ð½Ð°Ð´Ð°Ð½Ð¸Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚.

1. ÐšÐ¾Ð½Ñ‚ÐµÐºÑÑ‚:
{context}

2. Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ ÐÐ½Ð°Ð»Ñ–Ð·Ñƒ:

ÐŸÑ€Ð¾Ð²ÐµÐ´Ð¸ Ð³Ð»Ð¸Ð±Ð¾ÐºÐ¸Ð¹ Ð°Ð½Ð°Ð»Ñ–Ð· Ð·Ð° Ð½Ð°ÑÑ‚ÑƒÐ¿Ð½Ð¾ÑŽ ÑÑ‚Ñ€ÑƒÐºÑ‚ÑƒÑ€Ð¾ÑŽ Ñ‚Ð° Ð½Ð°Ð´Ð°Ð¹ Ð²Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð²Ð¸ÐºÐ»ÑŽÑ‡Ð½Ð¾ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– JSON.

Hook (0-3 ÑÐµÐºÑƒÐ½Ð´Ð¸): Ð’Ð¸Ð·Ð½Ð°Ñ‡ Ð¾ÑÐ½Ð¾Ð²Ð½Ð¸Ð¹ Ð³Ð°Ñ‡Ð¾Ðº. Ð¯ÐºÐ¸Ð¹ Ð¿ÑÐ¸Ñ…Ð¾Ð»Ð¾Ð³Ñ–Ñ‡Ð½Ð¸Ð¹ Ð¿Ñ€Ð¸Ð½Ñ†Ð¸Ð¿ Ð²Ñ–Ð½ Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ” (Ð½Ð°Ð¿Ñ€., Curiosity Gap, Social Proof, Loss Aversion, Shock)? ÐÐ°ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð²Ñ–Ð½ Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¸Ð¹ Ð´Ð»Ñ Ð¦Ð?

Ð’Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¡Ñ‚Ð¸Ð»ÑŒ Ñ‚Ð° Ð”Ð¸Ð½Ð°Ð¼Ñ–ÐºÐ°: ÐžÑ†Ñ–Ð½Ð¸ ÑÑ‚Ð¸Ð»ÑŒ, ÐµÑ„ÐµÐºÑ‚Ð¸ Ñ‚Ð° ÐºÐ¾Ð»ÑŒÐ¾Ñ€Ð¾Ð²Ñƒ Ð³Ð°Ð¼Ñƒ. Ð¯ÐºÐ¸Ð¹ Ñ‚ÐµÐ¼Ð¿ Ñƒ Ð²Ñ–Ð´ÐµÐ¾ (Ð¿Ð¾Ð²Ñ–Ð»ÑŒÐ½Ð¸Ð¹, ÑˆÐ²Ð¸Ð´ÐºÐ¸Ð¹, Ð·Ð¼Ñ–ÑˆÐ°Ð½Ð¸Ð¹)? Ð¯Ðº Ñ†Ðµ Ð²Ð¿Ð»Ð¸Ð²Ð°Ñ” Ð½Ð° ÑÐ¿Ñ€Ð¸Ð¹Ð½ÑÑ‚Ñ‚Ñ?

Ð¢ÐµÐºÑÑ‚ Ð½Ð° ÐµÐºÑ€Ð°Ð½Ñ– (OCR): Ð Ð¾Ð·Ð¿Ñ–Ð·Ð½Ð°Ð¹ Ñ‚Ð° Ð²Ð¸Ð¿Ð¸ÑˆÐ¸ Ð²ÐµÑÑŒ Ñ‚ÐµÐºÑÑ‚ Ð· ÐµÐºÑ€Ð°Ð½Ñƒ Ð· Ñ‚Ð°Ð¹Ð¼ÐºÐ¾Ð´Ð°Ð¼Ð¸.

ÐŸÐ¾ÐºÐ°Ð· ÐŸÑ€Ð¾Ð´ÑƒÐºÑ‚Ñƒ/Ð¦Ñ–Ð½Ð½Ð¾ÑÑ‚Ñ–: Ð¯Ðº Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ñƒ ÑÑŽÐ¶ÐµÑ‚? Ð§Ð¸ Ð¿Ð¾ÐºÐ°Ð·ÑƒÑŽÑ‚ÑŒ Ð»Ð¸ÑˆÐµ Ñ„Ñ–Ñ‡Ñ–, Ñ‡Ð¸ Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€ÑƒÑŽÑ‚ÑŒ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚/Ñ‚Ñ€Ð°Ð½ÑÑ„Ð¾Ñ€Ð¼Ð°Ñ†Ñ–ÑŽ Ð´Ð»Ñ ÐºÐ¾Ñ€Ð¸ÑÑ‚ÑƒÐ²Ð°Ñ‡Ð°?

CTA (Call-to-Action): ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ð·Ð°ÐºÐ»Ð¸Ðº Ð´Ð¾ Ð´Ñ–Ñ—. Ð§Ð¸ Ñ” Ð² Ð½ÑŒÐ¾Ð¼Ñƒ Ñ‚ÐµÑ€Ð¼Ñ–Ð½Ð¾Ð²Ñ–ÑÑ‚ÑŒ, Ð¾Ð±Ð¼ÐµÐ¶ÐµÐ½Ð½Ñ Ð°Ð±Ð¾ Ð´Ð¾Ð´Ð°Ñ‚ÐºÐ¾Ð²Ð¸Ð¹ ÑÑ‚Ð¸Ð¼ÑƒÐ» (incentive)?

ÐšÐ»ÑŽÑ‡Ð¾Ð²Ðµ ÐŸÐ¾Ð²Ñ–Ð´Ð¾Ð¼Ð»ÐµÐ½Ð½Ñ (Messaging): Ð¯ÐºÑ– Ð±Ð¾Ð»Ñ– Ð¦Ð Ð·Ð°Ñ‡Ñ–Ð¿Ð°ÑŽÑ‚ÑŒÑÑ Ñ– ÑÐºÑ– Ñ†Ñ–Ð½Ð½Ñ–ÑÐ½Ñ– Ð¿Ñ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ñ— (value props) Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‚ÑŒÑÑ ÑÐº Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ? Ð¯Ðº Ð²Ð¾Ð½Ð¸ ÑÑ„Ð¾Ñ€Ð¼ÑƒÐ»ÑŒÐ¾Ð²Ð°Ð½Ñ– (Ð½Ð°Ð¿Ñ€Ð¸ÐºÐ»Ð°Ð´, Ñ‡ÐµÑ€ÐµÐ· ÑÑ‚Ð¾Ñ€Ñ–Ñ‚ÐµÐ»Ñ–Ð½Ð³, Ð¿Ñ€ÑÐ¼Ðµ Ð·Ð²ÐµÑ€Ð½ÐµÐ½Ð½Ñ, Ð´ÐµÐ¼Ð¾Ð½ÑÑ‚Ñ€Ð°Ñ†Ñ–ÑŽ "Ð´Ð¾/Ð¿Ñ–ÑÐ»Ñ")?

ÐÑƒÐ´Ñ–Ð¾: ÐžÑ†Ñ–Ð½Ð¸ Ð¼ÑƒÐ·Ð¸ÐºÑƒ, Ð³Ð¾Ð»Ð¾Ñ Ñ‚Ð° Ð·Ð²ÑƒÐºÐ¾Ð²Ñ– ÐµÑ„ÐµÐºÑ‚Ð¸. Ð§Ð¸ Ð´Ð¾Ð¿Ð¾Ð²Ð½ÑŽÑŽÑ‚ÑŒ Ð²Ð¾Ð½Ð¸ Ð²Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€ÑÐ´ Ñ– Ð¿Ñ–Ð´ÑÐ¸Ð»ÑŽÑŽÑ‚ÑŒ ÐµÐ¼Ð¾Ñ†Ñ–Ñ—?

ÐÐ°Ñ€Ð°Ñ‚Ð¸Ð² Ñ‚Ð° Ð•Ð¼Ð¾Ñ†Ñ–Ð¹Ð½Ð¸Ð¹ Ð¨Ð»ÑÑ…: Ð Ð¾Ð·Ð±Ð¸Ð¹ Ð²Ñ–Ð´ÐµÐ¾ Ð½Ð° ÐºÐ»ÑŽÑ‡Ð¾Ð²Ñ– ÑÑ†ÐµÐ½Ð¸. Ð¯ÐºÑƒ ÐµÐ¼Ð¾Ñ†Ñ–Ð¹Ð½Ñƒ Ð¿Ð¾Ð´Ð¾Ñ€Ð¾Ð¶ Ð¿Ñ€Ð¾Ñ…Ð¾Ð´Ð¸Ñ‚ÑŒ Ð³Ð»ÑÐ´Ð°Ñ‡ (Ð½Ð°Ð¿Ñ€., Ð²Ñ–Ð´ Ñ–Ð½Ñ‚Ñ€Ð¸Ð³Ð¸ -> Ð´Ð¾ Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸ -> Ð´Ð¾ Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ -> Ð´Ð¾ Ð±Ð°Ð¶Ð°Ð½Ð¾Ð³Ð¾ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñƒ)?

ÐšÐ°Ñ€Ñ‚Ð° Ð¡Ð¸Ð»ÑŒÐ½Ð¸Ñ… Ñ‚Ð° Ð¡Ð»Ð°Ð±ÐºÐ¸Ñ… Ð¡Ñ‚Ð¾Ñ€Ñ–Ð½: ÐžÑ†Ñ–Ð½Ð¸ ÐºÐ»ÑŽÑ‡Ð¾Ð²Ñ– ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¸ Ð·Ð° ÑˆÐºÐ°Ð»Ð¾ÑŽ Ð²Ñ–Ð´ 0 Ð´Ð¾ 1, Ð´Ðµ 1 â€” Ð¼Ð°ÐºÑÐ¸Ð¼Ð°Ð»ÑŒÐ½Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ñ–ÑÑ‚ÑŒ.

ÐšÐ»ÑŽÑ‡Ð¾Ð²Ñ– Ð’Ð¸ÑÐ½Ð¾Ð²ÐºÐ¸ Ñ‚Ð° Ð“Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð¸: Ð¡Ñ„Ð¾Ñ€Ð¼ÑƒÐ»ÑŽÐ¹ Ð³Ð¾Ð»Ð¾Ð²Ð½Ñƒ ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–ÑŽ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ñƒ, ÐºÐ»ÑŽÑ‡Ð¾Ð²Ñ– Ñ–Ð½ÑÐ°Ð¹Ñ‚Ð¸ Ñ‚Ð° 2-3 ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ñ– Ð³Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð¸, ÑÐºÑ– Ð¼Ð¸ Ð¼Ð¾Ð¶ÐµÐ¼Ð¾ Ð¿Ñ€Ð¾Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ñ‚Ð¸ Ñƒ Ð½Ð°ÑˆÐ¸Ñ… Ð²Ð»Ð°ÑÐ½Ð¸Ñ… ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð°Ñ….

Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð²Ð¸ÐºÐ»ÑŽÑ‡Ð½Ð¾ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– JSON:
{{
  "hook": {{
    "time_start_s": 0.0,
    "time_end_s": 3.0,
    "description": "Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ Ð³Ð°Ñ‡ÐºÐ°",
    "psychological_principle": "Curiosity Gap / Social Proof / Loss Aversion / Shock / Ñ–Ð½ÑˆÐµ",
    "relevance_to_audience": "Ð¾Ñ†Ñ–Ð½ÐºÐ° Ñ€ÐµÐ»ÐµÐ²Ð°Ð½Ñ‚Ð½Ð¾ÑÑ‚Ñ– Ð´Ð»Ñ Ð¦Ð",
    "strength": 0.8
  }},
  "visual_style": {{
    "style": "UGC/screencast/motion graphics/real footage/Ñ–Ð½ÑˆÐµ",
    "effects": ["jump cuts", "zooms", "transitions", "filters"],
    "color_palette": "Ð¾Ð¿Ð¸Ñ ÐºÐ¾Ð»ÑŒÐ¾Ñ€Ð¾Ð²Ð¾Ñ— Ð³Ð°Ð¼Ð¸",
    "pacing": "slow/fast/mixed",
    "pacing_impact": "ÑÐº Ñ‚ÐµÐ¼Ð¿ Ð²Ð¿Ð»Ð¸Ð²Ð°Ñ” Ð½Ð° ÑÐ¿Ñ€Ð¸Ð¹Ð½ÑÑ‚Ñ‚Ñ",
    "has_captions": true/false,
    "caption_style": "Ð¾Ð¿Ð¸Ñ ÑÑ‚Ð¸Ð»ÑŽ ÑÑƒÐ±Ñ‚Ð¸Ñ‚Ñ€Ñ–Ð²"
  }},
  "on_screen_text": [
    {{"timecode_s": 1.5, "text": "Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÐµÐºÑ€Ð°Ð½Ñ–"}}
  ],
  "product_showcase": {{
    "type": "UI demo/Real product/Transformation/Result-focused/Feature-focused",
    "integration_quality": "Ð½Ð°ÑÐºÑ–Ð»ÑŒÐºÐ¸ Ð¿Ñ€Ð¸Ñ€Ð¾Ð´Ð½ÑŒÐ¾ Ñ–Ð½Ñ‚ÐµÐ³Ñ€Ð¾Ð²Ð°Ð½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚",
    "shows_transformation": true/false,
    "timecodes_s": [2.0, 5.5, 10.0],
    "key_features": ["feature1", "feature2"],
    "clarity_score": 0.7
  }},
  "cta": [
    {{
      "timecode_s": 12.0,
      "text": "Ñ‚Ð¾Ñ‡Ð½Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚ CTA",
      "channel": "on-screen/voice/both",
      "has_urgency": true/false,
      "has_incentive": true/false,
      "incentive_description": "Ð¾Ð¿Ð¸Ñ ÑÑ‚Ð¸Ð¼ÑƒÐ»Ñƒ, ÑÐºÑ‰Ð¾ Ñ”",
      "strength": 0.9
    }}
  ],
  "messaging": {{
    "pains": [
      {{"text": "Ð±Ñ–Ð»ÑŒ Ð¦Ð", "timecode_s": 1.0, "presentation_style": "storytelling/direct/visual"}}
    ],
    "value_props": [
      {{"text": "Ñ†Ñ–Ð½Ð½Ñ–ÑÐ½Ð° Ð¿Ñ€Ð¾Ð¿Ð¾Ð·Ð¸Ñ†Ñ–Ñ", "timecode_s": 3.5, "presentation_style": "before-after/testimonial/demonstration"}}
    ],
    "messaging_approach": "storytelling/direct address/problem-solution/before-after"
  }},
  "audio": {{
    "has_voiceover": true/false,
    "voiceover_tone": "Ð¾Ð¿Ð¸Ñ Ñ‚Ð¾Ð½Ñƒ Ð³Ð¾Ð»Ð¾ÑÑƒ",
    "music_mood": "energetic/calm/dramatic/uplifting/none",
    "sound_effects": true/false,
    "audio_visual_alignment": "ÑÐº Ð°ÑƒÐ´Ñ–Ð¾ Ð´Ð¾Ð¿Ð¾Ð²Ð½ÑŽÑ” Ð²Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ñ€ÑÐ´"
  }},
  "emotional_journey": [
    {{
      "scene": 1,
      "time_start_s": 0.0,
      "time_end_s": 3.0,
      "what_we_see": "Ð¾Ð¿Ð¸Ñ Ð²Ñ–Ð·ÑƒÐ°Ð»Ñƒ",
      "what_we_hear": "Ð¾Ð¿Ð¸Ñ Ð°ÑƒÐ´Ñ–Ð¾",
      "emotional_state": "intrigue/problem/solution/desire/action",
      "viewer_emotion": "ÑÐºÑƒ ÐµÐ¼Ð¾Ñ†Ñ–ÑŽ Ð²Ñ–Ð´Ñ‡ÑƒÐ²Ð°Ñ” Ð³Ð»ÑÐ´Ð°Ñ‡"
    }}
  ],
  "scores": {{
    "hook_strength": 0.8,
    "cta_clarity": 0.9,
    "product_visibility": 0.7,
    "message_density": 0.6,
    "execution_quality": 0.8,
    "emotional_impact": 0.7,
    "relevance_to_audience": 0.8
  }},
  "key_insights": {{
    "main_strategy": "Ð³Ð¾Ð»Ð¾Ð²Ð½Ð° ÑÑ‚Ñ€Ð°Ñ‚ÐµÐ³Ñ–Ñ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ñƒ Ð² 1-2 Ñ€ÐµÑ‡ÐµÐ½Ð½ÑÑ…",
    "key_insights": [
      "Ñ–Ð½ÑÐ°Ð¹Ñ‚ 1: Ñ‰Ð¾ Ñ€Ð¾Ð±Ð¸Ñ‚ÑŒ Ñ†ÐµÐ¹ ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð² ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¸Ð¼",
      "Ñ–Ð½ÑÐ°Ð¹Ñ‚ 2: ÐºÐ»ÑŽÑ‡Ð¾Ð²Ð° Ñ‚Ð°ÐºÑ‚Ð¸ÐºÐ° Ð°Ð±Ð¾ Ð¿Ñ–Ð´Ñ…Ñ–Ð´",
      "Ñ–Ð½ÑÐ°Ð¹Ñ‚ 3: ÑƒÐ½Ñ–ÐºÐ°Ð»ÑŒÐ½Ð¸Ð¹ ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚"
    ],
    "hypotheses_to_test": [
      "Ð“Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð° 1: ÐºÐ¾Ð½ÐºÑ€ÐµÑ‚Ð½Ð° Ñ–Ð´ÐµÑ Ð´Ð»Ñ Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ Ð² Ð½Ð°ÑˆÐ¸Ñ… ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ð°Ñ…",
      "Ð“Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð° 2: Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ð¸Ð¹ Ð¿Ñ–Ð´Ñ…Ñ–Ð´ Ð½Ð° Ð¾ÑÐ½Ð¾Ð²Ñ– Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ",
      "Ð“Ñ–Ð¿Ð¾Ñ‚ÐµÐ·Ð° 3: ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚ Ð´Ð»Ñ A/B Ñ‚ÐµÑÑ‚ÑƒÐ²Ð°Ð½Ð½Ñ"
    ]
  }},
  "summary": "ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ Ð°Ð½Ð°Ð»Ñ–Ð·Ñƒ Ð² 2-3 Ñ€ÐµÑ‡ÐµÐ½Ð½ÑÑ… Ð· Ñ„Ð¾ÐºÑƒÑÐ¾Ð¼ Ð½Ð° ÐµÑ„ÐµÐºÑ‚Ð¸Ð²Ð½Ð¾ÑÑ‚Ñ– Ñ‚Ð° Ð·Ð°ÑÑ‚Ð¾ÑÑƒÐ²Ð°Ð½Ð½Ñ–"
}}

ÐÐµ Ð²Ð¸Ð³Ð°Ð´ÑƒÐ¹: ÑÐºÑ‰Ð¾ Ñ‡Ð¾Ð³Ð¾ÑÑŒ Ð½Ðµ Ð²Ð¸Ð´Ð½Ð¾ Ð°Ð±Ð¾ Ð½Ðµ Ñ‡ÑƒÑ‚Ð¸ â€” Ð¿Ð¸ÑˆÐ¸ null Ð°Ð±Ð¾ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ–Ð¹ Ð¼Ð°ÑÐ¸Ð²."""

    # Generate analysis
    print("ðŸ¤– ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð²Ñ–Ð´ÐµÐ¾ Ð· Gemini...")
    response = model.generate_content(
        [video_file, prompt],
        generation_config={
            "temperature": 0.3,
            "response_mime_type": "application/json",
        }
    )
    
    # Parse JSON response
    try:
        result = json.loads(response.text)
        print("âœ… ÐÐ½Ð°Ð»Ñ–Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾")
        return result
    except json.JSONDecodeError as e:
        print(f"âš ï¸  JSON parse error: {e}")
        # Try to extract JSON from response
        import re
        m = re.search(r"\{[\s\S]*\}", response.text)
        if m:
            return json.loads(m.group(0))
        # Fallback
        return {
            "error": "Failed to parse JSON",
            "raw_response": response.text[:500]
        }


def analyze_video_prototype(video_path: str, output_path: Optional[str] = None) -> Dict[str, Any]:
    """
    Simple wrapper for prototype testing.
    
    Args:
        video_path: Path to video file
        output_path: Optional path to save JSON result
    
    Returns:
        Analysis dictionary
    """
    result = analyze_video_file(video_path)
    
    if output_path:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ðŸ’¾ Saved to: {output_path}")
    
    return result


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("Usage: python -m src.analysis.video_analyzer <video_path> [output_json]")
        sys.exit(1)
    
    video_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = analyze_video_prototype(video_path, output_path)
    print(json.dumps(result, ensure_ascii=False, indent=2))
