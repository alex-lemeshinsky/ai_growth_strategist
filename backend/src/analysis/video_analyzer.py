"""
Video analysis prototype using Gemini vision capabilities.
Extracts hooks, CTAs, visual elements, on-screen text, and product showcase from video ads.
"""
import os
import json
from typing import Dict, Any, Optional
from pathlib import Path

from dotenv import load_dotenv
import google.generativeai as genai

load_dotenv()
DEFAULT_MODEL = os.environ.get("GEMINI_MODEL", "models/gemini-2.0-flash")


def _ensure_api_key():
    api_key = os.environ.get("GOOGLE_API_KEY")
    if not api_key:
        raise RuntimeError("GOOGLE_API_KEY is not set. Please export your Google AI Studio API key.")
    genai.configure(api_key=api_key)


def analyze_video_file(
    video_path: str,
    meta: Optional[Dict[str, Any]] = None,
    model_name: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Analyze a video file using Gemini vision model.
    
    Args:
        video_path: Path to the cached video file
        meta: Optional metadata about the creative (page_name, platforms, etc.)
        model_name: Gemini model to use (default: gemini-1.5-flash)
    
    Returns:
        Dictionary with structured analysis
    """
    _ensure_api_key()
    
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"Video file not found: {video_path}")
    
    # Upload video to Gemini
    print(f"ðŸ“¤ Uploading video: {Path(video_path).name}")
    video_file = genai.upload_file(path=video_path)
    print(f"âœ… Uploaded as: {video_file.name}")
    
    # Wait for file to become active
    import time
    print("â³ Waiting for file to be processed...")
    while video_file.state.name == "PROCESSING":
        time.sleep(2)
        video_file = genai.get_file(video_file.name)
    
    if video_file.state.name != "ACTIVE":
        raise RuntimeError(f"File processing failed: {video_file.state.name}")
    print("âœ… File is ready")
    
    # Try to use specified model, fallback to working alternatives
    model_to_use = model_name or DEFAULT_MODEL
    
    # Ensure model name has correct prefix
    if not model_to_use.startswith("models/"):
        model_to_use = f"models/{model_to_use}"
    
    try:
        model = genai.GenerativeModel(model_to_use)
    except Exception as e:
        print(f"âš ï¸  Model {model_to_use} not available, trying models/gemini-2.0-flash...")
        try:
            model = genai.GenerativeModel("models/gemini-2.0-flash")
        except Exception:
            print("âš ï¸  Trying models/gemini-2.0-pro-exp...")
            model = genai.GenerativeModel("models/gemini-2.0-pro-exp")
    
    # Build context
    context = ""
    if meta:
        context = f"\nÐœÐµÑ‚Ð°Ð´Ð°Ð½Ñ– ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð²Ñƒ:\n{json.dumps(meta, ensure_ascii=False, indent=2)}\n"
    
    # Prompt for video analysis (Ukrainian)
    prompt = f"""ÐŸÑ€Ð¾Ð°Ð½Ð°Ð»Ñ–Ð·ÑƒÐ¹ Ñ†ÐµÐ¹ Ð²Ñ–Ð´ÐµÐ¾ÐºÑ€ÐµÐ°Ñ‚Ð¸Ð² ÐºÐ¾Ð½ÐºÑƒÑ€ÐµÐ½Ñ‚Ð° Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¾.

{context}

Ð—Ð°Ð²Ð´Ð°Ð½Ð½Ñ:
1. **Hook (0-3 ÑÐµÐº)**: Ð©Ð¾ Ð²Ñ–Ð´Ð±ÑƒÐ²Ð°Ñ”Ñ‚ÑŒÑÑ Ð² Ð¿ÐµÑ€ÑˆÑ– 3 ÑÐµÐºÑƒÐ½Ð´Ð¸? Ð¯ÐºÐ¸Ð¹ Ñ…ÑƒÐº Ð²Ð¸ÐºÐ¾Ñ€Ð¸ÑÑ‚Ð¾Ð²ÑƒÑ”Ñ‚ÑŒÑÑ? ÐÐ° ÑÐºÑ–Ð¹ ÑÐµÐºÑƒÐ½Ð´Ñ– Ñ‚Ð¾Ñ‡Ð½Ð¾? Ð¯ÐºÐ° Ñ‚Ð°ÐºÑ‚Ð¸ÐºÐ° (ÑˆÐ²Ð¸Ð´ÐºÑ– Ð·Ð¼Ñ–Ð½Ð¸, Ð·Ð°Ð¿Ð¸Ñ‚Ð°Ð½Ð½Ñ, bold claim, Ð´ÐµÐ¼Ð¾ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñƒ, Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð°)?

2. **Ð’Ñ–Ð·ÑƒÐ°Ð»ÑŒÐ½Ñ– ÐµÐ»ÐµÐ¼ÐµÐ½Ñ‚Ð¸**: 
   - Ð¡Ñ‚Ð¸Ð»ÑŒ (UGC, screencast, motion graphics, real footage)?
   - Ð•Ñ„ÐµÐºÑ‚Ð¸ (jump cuts, zooms, transitions, filters)?
   - Ð¡ÑƒÐ±Ñ‚Ð¸Ñ‚Ñ€Ð¸/Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÐµÐºÑ€Ð°Ð½Ñ– (Ñ”/Ð½ÐµÐ¼Ð°Ñ”, ÑÑ‚Ð¸Ð»ÑŒ, ÐºÐ¾Ð»Ñ–Ñ€)?
   - ÐšÐ¾Ð»Ñ–Ñ€/Ð½Ð°ÑÑ‚Ñ€Ñ–Ð¹ (ÑÑÐºÑ€Ð°Ð²Ñ–/Ñ‚ÐµÐ¼Ð½Ñ–/Ð¼Ñ–Ð½Ñ–Ð¼Ð°Ð»Ñ–Ð·Ð¼)?

3. **Ð¢ÐµÐºÑÑ‚ Ð½Ð° ÐµÐºÑ€Ð°Ð½Ñ– (OCR)**: Ð’Ð¸Ð¿Ð¸ÑˆÐ¸ Ð²ÐµÑÑŒ Ð²Ð¸Ð´Ð¸Ð¼Ð¸Ð¹ Ñ‚ÐµÐºÑÑ‚ Ð· ÐµÐºÑ€Ð°Ð½Ñƒ Ð¿Ð¾ Ñ‚Ð°Ð¹Ð¼ÐºÐ¾Ð´Ð°Ñ… (ÑÐºÑ‰Ð¾ Ñ”).

4. **ÐŸÐ¾ÐºÐ°Ð· Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñƒ**:
   - Ð¯Ðº Ð¿Ð¾ÐºÐ°Ð·ÑƒÑŽÑ‚ÑŒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚ (UI Ð´ÐµÐ¼Ð¾, Ñ€ÐµÐ°Ð»ÑŒÐ½Ð¸Ð¹ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚, Ð´Ð¾/Ð¿Ñ–ÑÐ»Ñ, Ñ‚Ñ–Ð»ÑŒÐºÐ¸ Ñ‚ÐµÐºÑÑ‚)?
   - ÐÐ° ÑÐºÐ¸Ñ… ÑÐµÐºÑƒÐ½Ð´Ð°Ñ… Ð¿Ð¾ÐºÐ°Ð·ÑƒÑŽÑ‚ÑŒ UI/Ñ„ÑƒÐ½ÐºÑ†Ñ–Ñ—?
   - Ð¯ÐºÑ– ÐºÐ»ÑŽÑ‡Ð¾Ð²Ñ– Ñ„Ñ–Ñ‡Ñ– Ð¿Ñ–Ð´ÐºÑ€ÐµÑÐ»ÑŽÑŽÑ‚ÑŒ?

5. **CTA (Call-to-Action)**:
   - Ð”Ðµ Ð·'ÑÐ²Ð»ÑÑ”Ñ‚ÑŒÑÑ CTA (Ð³Ð¾Ð»Ð¾Ñ, Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÐµÐºÑ€Ð°Ð½Ñ–, ÐºÑ–Ð½Ñ†ÐµÐ²Ð° Ð·Ð°ÑÑ‚Ð°Ð²ÐºÐ°)?
   - Ð¢Ð¾Ñ‡Ð½Ð¸Ð¹ Ñ‚Ð°Ð¹Ð¼ÐºÐ¾Ð´ Ñ– Ñ‚ÐµÐºÑÑ‚ CTA?
   - Ð§Ð¸ Ð¿Ð¾Ð²Ñ‚Ð¾Ñ€ÑŽÑ”Ñ‚ÑŒÑÑ?

6. **Ð‘Ð¾Ð»Ñ–/Value Props**:
   - Ð¯ÐºÑ– Ð¿Ñ€Ð¾Ð±Ð»ÐµÐ¼Ð¸/Ð±Ð¾Ð»Ñ– Ð¿Ð¾ÐºÐ°Ð·ÑƒÑŽÑ‚ÑŒ Ð°Ð±Ð¾ Ð·Ð³Ð°Ð´ÑƒÑŽÑ‚ÑŒ?
   - Ð¯ÐºÑ– Ð¿ÐµÑ€ÐµÐ²Ð°Ð³Ð¸/Ñ€Ñ–ÑˆÐµÐ½Ð½Ñ Ð¿Ñ€Ð¾Ð¿Ð¾Ð½ÑƒÑŽÑ‚ÑŒ?

7. **ÐœÑƒÐ·Ð¸ÐºÐ°/Ð—Ð²ÑƒÐº**:
   - ÐÐ°ÑÑ‚Ñ€Ñ–Ð¹ Ð¼ÑƒÐ·Ð¸ÐºÐ¸ (ÐµÐ½ÐµÑ€Ð³Ñ–Ð¹Ð½Ð°, ÑÐ¿Ð¾ÐºÑ–Ð¹Ð½Ð°, Ð´Ñ€Ð°Ð¼Ð°Ñ‚Ð¸Ñ‡Ð½Ð°)?
   - Ð§Ð¸ Ñ” Ð·Ð°ÐºÐ°Ð´Ñ€Ð¾Ð²Ð¸Ð¹ Ð³Ð¾Ð»Ð¾Ñ?
   - Ð—Ð²ÑƒÐºÐ¾Ð²Ñ– ÐµÑ„ÐµÐºÑ‚Ð¸?

8. **ÐŸÐ¾ÐºÐ°Ð´Ñ€Ð¾Ð²Ð¸Ð¹ ÑÑ‚Ð¾Ñ€Ñ–Ð±Ð¾Ñ€Ð´** (Ð¿Ð¾ ÑÑ†ÐµÐ½Ð°Ñ…):
   - Ð¡Ñ†ÐµÐ½Ð° 1 (0-X ÑÐµÐº): Ñ‰Ð¾ Ð±Ð°Ñ‡Ð¸Ð¼Ð¾, Ñ‰Ð¾ Ñ‡ÑƒÑ”Ð¼Ð¾
   - Ð¡Ñ†ÐµÐ½Ð° 2 (X-Y ÑÐµÐº): Ñ‰Ð¾ Ð±Ð°Ñ‡Ð¸Ð¼Ð¾, Ñ‰Ð¾ Ñ‡ÑƒÑ”Ð¼Ð¾
   - ... (Ð´Ð»Ñ ÐºÐ¾Ð¶Ð½Ð¾Ñ— Ð·Ð¼Ñ–Ð½Ð¸ ÑÑ†ÐµÐ½Ð¸)

9. **Ð—Ð°Ð³Ð°Ð»ÑŒÐ½Ð° Ð¾Ñ†Ñ–Ð½ÐºÐ°** (0-1):
   - Ð¡Ð¸Ð»Ð° Ñ…ÑƒÐºÐ°
   - Ð§Ñ–Ñ‚ÐºÑ–ÑÑ‚ÑŒ CTA
   - Ð’Ð¸Ð´Ð¸Ð¼Ñ–ÑÑ‚ÑŒ Ð¿Ñ€Ð¾Ð´ÑƒÐºÑ‚Ñƒ
   - Ð©Ñ–Ð»ÑŒÐ½Ñ–ÑÑ‚ÑŒ Ð¼ÐµÑÐµÐ´Ð¶Ñ–Ð²
   - Ð¯ÐºÑ–ÑÑ‚ÑŒ Ð²Ð¸ÐºÐ¾Ð½Ð°Ð½Ð½Ñ

Ð’Ñ–Ð´Ð¿Ð¾Ð²Ñ–Ð´ÑŒ Ð²Ð¸ÐºÐ»ÑŽÑ‡Ð½Ð¾ Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ– JSON:
{{
  "hook": {{
    "time_start_s": 0.0,
    "time_end_s": 3.0,
    "description": "Ð´ÐµÑ‚Ð°Ð»ÑŒÐ½Ð¸Ð¹ Ð¾Ð¿Ð¸Ñ",
    "tactic": "Ð½Ð°Ð·Ð²Ð° Ñ‚Ð°ÐºÑ‚Ð¸ÐºÐ¸",
    "strength": 0.8
  }},
  "visual_style": {{
    "style": "UGC/screencast/etc",
    "effects": ["effect1", "effect2"],
    "has_captions": true/false,
    "caption_style": "Ð¾Ð¿Ð¸Ñ ÑÑ‚Ð¸Ð»ÑŽ",
    "color_mood": "Ð¾Ð¿Ð¸Ñ"
  }},
  "on_screen_text": [
    {{"timecode_s": 1.5, "text": "Ñ‚ÐµÐºÑÑ‚ Ð½Ð° ÐµÐºÑ€Ð°Ð½Ñ–"}},
    {{"timecode_s": 5.0, "text": "Ñ–Ð½ÑˆÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚"}}
  ],
  "product_showcase": {{
    "type": "UI demo/Real product/Before-After/Text only",
    "timecodes_s": [2.0, 5.5, 10.0],
    "key_features": ["feature1", "feature2"],
    "clarity_score": 0.7
  }},
  "cta": [
    {{
      "timecode_s": 12.0,
      "text": "Download Now",
      "channel": "on-screen/voice/both",
      "strength": 0.9
    }}
  ],
  "pains": [
    {{"text": "Ð¾Ð¿Ð¸Ñ Ð±Ð¾Ð»ÑŽ", "timecode_s": 1.0}}
  ],
  "value_props": [
    {{"text": "Ð¾Ð¿Ð¸Ñ Ð¿ÐµÑ€ÐµÐ²Ð°Ð³Ð¸", "timecode_s": 3.5}}
  ],
  "audio": {{
    "has_voiceover": true/false,
    "music_mood": "energetic/calm/dramatic/none",
    "sound_effects": true/false
  }},
  "storyboard": [
    {{
      "scene": 1,
      "time_start_s": 0.0,
      "time_end_s": 3.0,
      "what_we_see": "Ð¾Ð¿Ð¸Ñ Ð²Ñ–Ð·ÑƒÐ°Ð»Ñƒ",
      "what_we_hear": "Ð¾Ð¿Ð¸Ñ Ð°ÑƒÐ´Ñ–Ð¾"
    }}
  ],
  "scores": {{
    "hook_strength": 0.8,
    "cta_clarity": 0.9,
    "product_visibility": 0.7,
    "message_density": 0.6,
    "execution_quality": 0.8
  }},
  "summary": "ÐºÐ¾Ñ€Ð¾Ñ‚ÐºÐµ Ñ€ÐµÐ·ÑŽÐ¼Ðµ 2-3 Ñ€ÐµÑ‡ÐµÐ½Ð½Ñ"
}}

ÐÐµ Ð²Ð¸Ð³Ð°Ð´ÑƒÐ¹: ÑÐºÑ‰Ð¾ Ñ‡Ð¾Ð³Ð¾ÑÑŒ Ð½Ðµ Ð²Ð¸Ð´Ð½Ð¾ Ð°Ð±Ð¾ Ð½Ðµ Ñ‡ÑƒÑ‚Ð¸ â€” Ð¿Ð¸ÑˆÐ¸ null Ð°Ð±Ð¾ Ð¿Ð¾Ñ€Ð¾Ð¶Ð½Ñ–Ð¹ Ð¼Ð°ÑÐ¸Ð²."""

    # Generate analysis
    print("ðŸ¤– ÐÐ½Ð°Ð»Ñ–Ð·ÑƒÑŽ Ð²Ñ–Ð´ÐµÐ¾ Ð· Gemini...")
    response = model.generate_content(
        [video_file, prompt],
        generation_config={
            "temperature": 0.3,
            "response_mime_type": "application/json",
        }
    )
    
    # Parse JSON response
    try:
        result = json.loads(response.text)
        print("âœ… ÐÐ½Ð°Ð»Ñ–Ð· Ð·Ð°Ð²ÐµÑ€ÑˆÐµÐ½Ð¾")
        return result
    except json.JSONDecodeError as e:
        print(f"âš ï¸  JSON parse error: {e}")
        # Try to extract JSON from response
        import re
        m = re.search(r"\{[\s\S]*\}", response.text)
        if m:
            return json.loads(m.group(0))
        # Fallback
        return {
            "error": "Failed to parse JSON",
            "raw_response": response.text[:500]
        }


def analyze_video_prototype(video_path: str, output_path: Optional[str] = None) -> Dict[str, Any]:
    """
    Simple wrapper for prototype testing.
    
    Args:
        video_path: Path to video file
        output_path: Optional path to save JSON result
    
    Returns:
        Analysis dictionary
    """
    result = analyze_video_file(video_path)
    
    if output_path:
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        print(f"ðŸ’¾ Saved to: {output_path}")
    
    return result


if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("Usage: python -m src.analysis.video_analyzer <video_path> [output_json]")
        sys.exit(1)
    
    video_path = sys.argv[1]
    output_path = sys.argv[2] if len(sys.argv) > 2 else None
    
    result = analyze_video_prototype(video_path, output_path)
    print(json.dumps(result, ensure_ascii=False, indent=2))
